<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="description" content="Homepage" />
    <meta name="keywords" content="Homepage" />
    <meta name="author" content="Lart Pang" />
    <title>Binglu Wang</title>

    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma@0.9.4/css/bulma.min.css" />
    <link rel="apple-touch-icon" href="apple-touch-icon.png" />
    <link rel="icon" href="favicon.ico" />
</head>

<body>
    <section class="section has-background-white-ter">
        <div class="container" id="main">
            <div class="tile is-ancestor">
                <div class="tile is-parent is-3 is-vertical" id="header">
                    <div class="tile is-child is-vertical">
                        <div class="card">
                            <div class="card-image">
                                <figure class="image is-1by1" id="avatar">
                                    <img src="img\wbl.png" alt="avatar" />
                                </figure>
                            </div>

                            <div class="card-content" id="introduction">
                                <p class="title is-2">Binglu Wang</p>
                                <p class="title is-2">王秉路</p>

                                <div class="block">
                                    I received the Ph.D. degree in Control Science and Engineering with the School of Automation at Northwestern Polytechnic University, in 2021. I am currently a Post-doctoral with the Beijing Institute of Technology.
                                </div>

                                <div class="block" id="social-link">
                                    <ul>
                                        <li><a href="#" target="_blank">E-mail:</a>wbl921129@gmail.com</li>
                                        <!-- <li><a href="#" target="_blank">Tel:</a>18629291129</li> -->
                                    </ul>
                                </div>

                                <div class="block" id="social-link">
                                    <ul>
                                        <li><a href="https://scholar.google.com/citations?user=-eey0pkAAAAJ&hl=zh-CN" target="_blank">Google Scholar</a></li>
                                        <li><a href="https://github.com/CodeMonsterPHD" target="_blank">GitHub</a></li>
                                    </ul>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>

                <div class="tile is-parent is-9 is-vertical" id="information">
                    <div class="box" id="project">
                        <p class="title is-3">About Me</p>

                        <p class="is-size-6 is-uppercase is-italic has-text-weight-bold">2017 - 2021</p>
                        <ul class="ml-4">
                            <li style="font-size: larger;">Ph.D student, School of Automation, Northwestern Polytechnical University (NWPU)</li>
                        </ul>

                        <p class="is-size-6 is-uppercase is-italic has-text-weight-bold">February 2022 - present</p>
                        <ul class="ml-4">
                            <li style="font-size: larger;">Postdoctoral, Beijing Institute of Technology (BIT), Collaborating mentors: Erke Mao, Teng Long</li>
                        </ul>

                        <p class="is-size-6 is-uppercase is-italic has-text-weight-bold">December 2021 - present</p>
                        <ul class="ml-4">
                            <li style="font-size: larger;">Associate Professor, College of Information and Control Engineering, Xi'an University of Architecture and Technology</li>
                        </ul>
                    </div>

                    <div class="box" id="project">
                        <p class="title is-3">Reaserch Interests</p>

                        <p class="is-size-6 is-uppercase is-italic has-text-weight-bold">
                            Autopilot, Signal Processing, Computer Vision</p>
                        <ul class="ml-4">
                            <li style="font-size: larger;">
                                At present, we mainly use the camera-lidar fusion method for depth completion, object detection, semantic segmentation, tracking and online cross-sensor calibration, and design the fusion of multiple modalities according to different vision tasks.
                                Optimize the processing of different modal signals collected by different sensors such as cameras and lidars. Aiming at how to model vehicle-road collaboration in the same coordinate system, how to realize the signals collected by multiple sensors at the vehicle end and road end to work in 4D space and other directions.
                            </li>
                        </ul>

                        <p class="is-size-6 is-uppercase is-italic has-text-weight-bold">Remote sensing image processing</p>
                        <ul class="ml-4">
                            <li style="font-size: larger;">My research on remote sensing images mainly includes object detection and low-level remote sensing image super-resolution</li>
                        </ul>

                        <p class="is-size-6 is-uppercase is-italic has-text-weight-bold">Medical Image Processing</p>
                        <ul class="ml-4">
                            <li style="font-size: larger;">Apply image processing technology to analyze, process and interpret various image data in the medical field, so as to help doctors diagnose and treat diseases more accurately, and at the same time improve medical efficiency and reduce medical costs. </li>
                        </ul>
                    </div>


                    <div class="box" id="Publication">
                        <p class="title is-3">Publication</p>




                        <div class="media">
                            <figure class="media-left">
                                <p class="image is-64x64">
                                    <img src="img/4.jpg" />
                                </p>
                            </figure>
                            <div class="media-content">
                                <p class="paper-title" style="font-size: large; font-weight: 500; color: black;">
                                    Temporal Action Localization in the Deep Learning Era: A Survey
                                </p>
                                <p class="paper-title">
                                    <i>IEEE Transactions on Pattern Analysis and Machine Intelligence, 2023</i>
                                </p>
                                <p class="paper-author is-italic">
                                    <strong>Binglu Wang</strong>, Yongqiang Zhao, Le Yang, Teng Long, Xuelong Li
                                </p>

                                <p class="paper-info">
                                    <a href="https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=-eey0pkAAAAJ&citation_for_view=-eey0pkAAAAJ:4TOpqqG69KYC" target="_blank">[Paper]</a>
                                    <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:kS3B2yUIuQMJ:scholar.google.com/&output=citation&scisdr=ClG13cpmEIr-8CJOGfE:AFWwaeYAAAAAZYFIAfFLUpdIyeV_9k6ErulwCkg&scisig=AFWwaeYAAAAAZYFIAV4EC8-jao4sVSYxeFQhiR8&scisf=4&ct=citation&cd=-1&hl=zh-CN" target="_blank">[Bibtex]</a>
                                </p>
                            </div>
                        </div>



                        <div class="media">
                            <figure class="media-left">
                                <p class="image is-64x64">
                                    <img src="img/4.jpg" />
                                </p>
                            </figure>
                            <div class="media-content">
                                <p class="paper-title" style="font-size: large; font-weight: 500; color: black;">
                                    Coarse-to-Fine Nutrition Prediction
                                </p>
                                <p class="paper-title">
                                    <i>IEEE Transactions on Multimedia, 2023</i>
                                </p>
                                <p class="paper-author is-italic">
                                   Binglu Wang, Tianci Bu, Zaiyi Hu, Yongqiang Zhao, Xuelong Li
                                </p>

                                <p class="paper-info">
                                    <a href="https://ieeexplore.ieee.org/abstract/document/10246427/" target="_blank">[Paper]</a>
                                    <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:U7ady5MMsnEJ:scholar.google.com/&output=citation&scisdr=ClG13cpmEIr-8CJPUyw:AFWwaeYAAAAAZYFJSyyNQG1NwFCadurHasb_Hx4&scisig=AFWwaeYAAAAAZYFJS5A_yBx8UtXAQ9-JmZfOqUo&scisf=4&ct=citation&cd=-1&hl=zh-CN" target="_blank">[Bibtex]</a>
                                </p>
                            </div>
                        </div>

                        <div class="media">
                            <figure class="media-left">
                                <p class="image is-64x64">
                                    <img src="img/4.jpg" />
                                </p>
                            </figure>
                            <div class="media-content">
                                <p class="paper-title" style="font-size: large; font-weight: 500; color: black;">
                                    Joint Denoising-Demosaicking Network for Long-Wave Infrared Division-of-Focal-Plane Polarization Images with Mixed Noise Level Estimation
                                </p>
                                <p class="paper-title">
                                    <i>IEEE Transactions on Image Processing, 2023</i>
                                </p>
                                <p class="paper-author is-italic">
                                    Ning Li, Binglu Wang*, François Goudail, Yongqiang Zhao, Quan Pan
                                </p>

                                <p class="paper-info">
                                    <a href="https://ieeexplore.ieee.org/abstract/document/10304085/" target="_blank">[Paper]</a>
                                    <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:taAbyZtOy0kJ:scholar.google.com/&output=citation&scisdr=ClG13cpmEIr-8CJPpCY:AFWwaeYAAAAAZYFJvCZmMDjTOcC4KX89LUjg7NM&scisig=AFWwaeYAAAAAZYFJvJMkiWpD3csHPp4fjuIk9Hc&scisf=4&ct=citation&cd=-1&hl=zh-CN" target="_blank">[Bibtex]</a>
                                </p>
                            </div>
                        </div>


                        <div class="media">
                            <figure class="media-left">
                                <p class="image is-64x64">
                                    <img src="img/4.jpg" />
                                </p>
                            </figure>
                            <div class="media-content">
                                <p class="paper-title" style="font-size: large; font-weight: 500; color: black;">
                                    Enhanced dynamic feature representation learning framework by Fourier transform for domain generalization
                                </p>
                                <p class="paper-title">
                                    <i>Information Sciences, 2023</i>
                                </p>
                                <p class="paper-author is-italic">
                                    Xin Wang, Qingjie Zhao, Changchun Zhang, Binglu Wang, Lei Wang, Wangwang Liu
                                </p>

                                <p class="paper-info">
                                    <a href="https://www.sciencedirect.com/science/article/pii/S0020025523012094" target="_blank">[Paper]</a>
                                    <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:BJ7lZ9jj0FwJ:scholar.google.com/&output=citation&scisdr=ClG13cpmEIr-8CJNme8:AFWwaeYAAAAAZYFLge-65g7xhxSe2-cWIwvWiuY&scisig=AFWwaeYAAAAAZYFLgdJmDFCMzQaXZENff3UfXzE&scisf=4&ct=citation&cd=-1&hl=zh-CN" target="_blank">[Bibtex]</a>
                                </p>
                            </div>
                        </div>


                        <div class="media">
                            <figure class="media-left">
                                <p class="image is-64x64">
                                    <img src="img/4.jpg" />
                                </p>
                            </figure>
                            <div class="media-content">
                                <p class="paper-title" style="font-size: large; font-weight: 500; color: black;">
                                    DSLSM: Dual-kernel-induced statistic level set model for image segmentation
                                </p>
                                <p class="paper-title">
                                    <i>Expert Systems with Applications, 2023</i>
                                </p>
                                <p class="paper-author is-italic">
                                    Fan Zhang, Huiying Liu, Xiaojun Duan, Binglu Wang, Qing Cai, Huafeng Li, Junyu Dong, David Zhang
                                </p>

                                <p class="paper-info">
                                    <a href="https://www.sciencedirect.com/science/article/pii/S0957417423032748" target="_blank">[Paper]</a>
                                    <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:YhAQ-QvyHScJ:scholar.google.com/&output=citation&scisdr=ClG13cpmEIr-8CJKJ_s:AFWwaeYAAAAAZYFMP_vtzCxzkHAkycbKDTcDDm8&scisig=AFWwaeYAAAAAZYFMP-dotB8Uh8Ebf4oFT1D547Y&scisf=4&ct=citation&cd=-1&hl=zh-CN" target="_blank">[Bibtex]</a>
                                </p>
                            </div>
                        </div>


                        <div class="media">
                            <figure class="media-left">
                                <p class="image is-64x64">
                                    <img src="img/4.jpg" />
                                </p>
                            </figure>
                            <div class="media-content">
                                <p class="paper-title" style="font-size: large; font-weight: 500; color: black;">
                                    Cross-Spatial Pixel Integration and Cross-Stage Feature Fusion Based Transformer Network for Remote Sensing Image Super-Resolution
                                </p>
                                <p class="paper-title">
                                    <i>IEEE Transactions on Geoscience and Remote Sensing, 2023</i>
                                </p>
                                <p class="paper-author is-italic">
                                    Yuting Lu, Lingtong Min, Binglu Wang*, Le Zheng, Xiaoxu Wang, Yongqiang Zhao, Teng Long
                                </p>

                                <p class="paper-info">
                                    <a href="https://ieeexplore.ieee.org/abstract/document/10323091/" target="_blank">[Paper]</a>
                                    <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:AX0g3RI6PTMJ:scholar.google.com/&output=citation&scisdr=ClG13cpmEIr-8CJK3DY:AFWwaeYAAAAAZYFMxDZVtA3eAA8y01Ap3C0NVas&scisig=AFWwaeYAAAAAZYFMxKyzgOAz4gzJqXC0zLSZ3-Q&scisf=4&ct=citation&cd=-1&hl=zh-CN" target="_blank">[Bibtex]</a>
                                </p>
                            </div>
                        </div>


                        <div class="media">
                            <figure class="media-left">
                                <p class="image is-64x64">
                                    <img src="img/4.jpg" />
                                </p>
                            </figure>
                            <div class="media-content">
                                <p class="paper-title" style="font-size: large; font-weight: 500; color: black;">
                                    A Dual-Attention Deep Discriminative Domain Generalization Model for Hyperspectral Image Classification
                                </p>
                                <p class="paper-title">
                                    <i>Information Sciences, 2023</i>
                                </p>
                                <p class="paper-author is-italic">
                                    Qingjie Zhao, Xin Wang, Binglu Wang, Lei Wang, Wangwang Liu, Shanshan Li
                                </p>

                                <p class="paper-info">
                                    <a href="https://www.mdpi.com/2072-4292/15/23/5492" target="_blank">[Paper]</a>
                                    <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:QhC5LR-bpP4J:scholar.google.com/&output=citation&scisdr=ClG13cpmEIr-8CJLaRY:AFWwaeYAAAAAZYFNcRZ7WANLg2Fffk8OQi-QOQY&scisig=AFWwaeYAAAAAZYFNcaygNFHxxjvZtt0KRhkGvWs&scisf=4&ct=citation&cd=-1&hl=zh-CN" target="_blank">[Bibtex]</a>
                                </p>
                            </div>
                        </div>


                        <div class="media">
                            <figure class="media-left">
                                <p class="image is-64x64">
                                    <img src="img/4.jpg" />
                                </p>
                            </figure>
                            <div class="media-content">
                                <p class="paper-title" style="font-size: large; font-weight: 500; color: black;">
                                    PneumoLLM: Harnessing the Power of Large Language Model for Pneumoconiosis Diagnosis
                                </p>
                                <p class="paper-title">
                                    <i>arXiv preprint arXiv:2312.03490</i>
                                </p>
                                <p class="paper-author is-italic">
                                    Meiyue Song, Zhihua Yu, Jiaxin Wang, Jiarui Wang, Yuting Lu, Baicun Li, Xiaoxu Wang, Qinghua Huang, Zhijun Li, Nikolaos I Kanellakis, Jiangfeng Liu, Jing Wang, Binglu Wang, Juntao Yang
                                </p>

                                <p class="paper-info">
                                    <a href="https://arxiv.org/abs/2312.03490" target="_blank">[Paper]</a>
                                    <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:rSiRxGx0L2YJ:scholar.google.com/&output=citation&scisdr=ClG13cpmEIr-8CJL9-8:AFWwaeYAAAAAZYFN7-9YM5ljdqyfOg7Qynw9caM&scisig=AFWwaeYAAAAAZYFN73n7-Hawtkl2fzPyCqnd5_s&scisf=4&ct=citation&cd=-1&hl=zh-CN" target="_blank">[Bibtex]</a>
                                </p>
                            </div>
                        </div>

                        <div class="media">
                            <figure class="media-left">
                                <p class="image is-64x64">
                                    <img src="img/4.jpg" />
                                </p>
                            </figure>
                            <div class="media-content">
                                <p class="paper-title" style="font-size: large; font-weight: 500; color: black;">
                                    YOLO-DCTI: Small Object Detection in Remote Sensing Base on Contextual Transformer Enhancement
                                </p>
                                <p class="paper-title">
                                    <i>Information Sciences, 2023</i>
                                </p>
                                <p class="paper-author is-italic">
                                    Lingtong Min, Ziman Fan, Qinyi Lv, Mohamed Reda, Linghao Shen, Binglu Wang
                                </p>

                                <p class="paper-info">
                                    <a href="https://www.mdpi.com/2072-4292/15/16/3970" target="_blank">[Paper]</a>
                                    <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:mt39Pc8mD34J:scholar.google.com/&output=citation&scisdr=ClG13cpmEIr-8CJIUlc:AFWwaeYAAAAAZYFOSle-sOIL4_CYSWEE_fSO4qA&scisig=AFWwaeYAAAAAZYFOSqMw7JIH-2XFaxN8GEeEMys&scisf=4&ct=citation&cd=-1&hl=zh-CN" target="_blank">[Bibtex]</a>
                                </p>
                            </div>
                        </div>

                        

                        <div class="media">
                            <figure class="media-left">
                                <p class="image is-64x64">
                                    <img src="img/4.jpg" />
                                </p>
                            </figure>
                            <div class="media-content">
                                <p class="paper-title" style="font-size: large; font-weight: 500; color: black;">
                                    Learning Pixel-Adaptive Weights for Portrait Photo Retouching
                                </p>
                                <p class="paper-title">
                                    <i>Pattern Recognition, 2023</i>
                                </p>
                                <p class="paper-author is-italic">
                                    <strong>Binglu Wang</strong>, Chengzhe Lu, Dawei Yan, Yongqiang Zhao, Ning Li, Xuelong Li
                                </p>

                                <p class="paper-info">
                                    <a href="https://www.sciencedirect.com/science/article/abs/pii/S0031320323004739" target="_blank">[Paper]</a>
                                    <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:NnurjHiGXkAJ:scholar.google.com/&output=citation&scisdr=ChUMH1XFEJ-q1Cz-oHY:ABFrs3wAAAAAZLT4uHaYWLQzYNEcxptBtCrox1s&scisig=ABFrs3wAAAAAZLT4uHY9b4BKSMA4YRszWzhqGUU&scisf=4&ct=citation&cd=-1&hl=zh-CN" target="_blank">[Bibtex]</a>
                                    <a href="https://github.com/CodeMonsterPHD/PWA" target="_blank">[Code]</a>
                                </p>
                            </div>
                        </div>

                        <div class="media">
                            <figure class="media-left">
                                <p class="image is-64x64">
                                    <img src="img/3.PNG" />
                                </p>
                            </figure>
                            <div class="media-content">
                                <p class="paper-title" style="font-size: large; font-weight: 500; color: black;">
                                    Prototype-based Intent Perception
                                </p>
                                <p class="paper-title">
                                    <i>IEEE Transactions on Multimedia, 2023</i>
                                </p>
                                <p class="paper-author is-italic">
                                    <strong>Binglu Wang</strong>, Kang Yang, Yongqiang Zhao, Teng Long, Xuelong Li
                                </p>

                                <p class="paper-info">
                                    <a href="https://ieeexplore.ieee.org/abstract/document/10008081" target="_blank">[Paper]</a>
                                    <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:E89JtwbcQa4J:scholar.google.com/&output=citation&scisdr=ChUMH1XFEJ-q1Cz-dI4:ABFrs3wAAAAAZLT4bI7w-bRudd4tPDTLW4a3ZAM&scisig=ABFrs3wAAAAAZLT4bE9g5IG7fHVNjdZF4GwjfzU&scisf=4&ct=citation&cd=-1&hl=zh-CN" target="_blank">[Bibtex]</a>
                                    <a href="https://github.com/CodeMonsterPHD/PIP-Net" target="_blank">[Code]</a>
                                </p>
                            </div>
                        </div>

                        <div class="media">
                            <figure class="media-left">
                                <p class="image is-64x64">
                                    <img src="img/8.gif" />
                                </p>
                            </figure>
                            <div class="media-content">
                                <p class="paper-title" style="font-size: large; font-weight: 500; color: black;">
                                    Hybrid Attention-Based U-Shaped Network for Remote Sensing Image Super-Resolution
                                </p>
                                <p class="paper-title">
                                    <i>IEEE Transactions on Geoscience and Remote Sensing, 2023</i>
                                </p>
                                <p class="paper-author is-italic">
                                    Jiarui Wang, <strong>Binglu Wang*</strong>, Xiaoxu Wang, Yongqiang Zhao and Teng Long
                                </p>

                                <p class="paper-info">
                                    <a href="https://ieeexplore.ieee.org/abstract/document/10145829" target="_blank">[Paper]</a>
                                    <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:iBV3oDjL2RwJ:scholar.google.com/&output=citation&scisdr=ChUMH1XLEJ-q1Cz_tdA:ABFrs3wAAAAAZLT5rdDQZ_74wEkRKLThfGZeXuM&scisig=ABFrs3wAAAAAZLT5rQsX03a8nqEY5aXoUXHr5Vs&scisf=4&ct=citation&cd=-1&hl=zh-CN" target="_blank">[Bibtex]</a>
                                    <a href="https://github.com/CodeMonsterPHD/HAUNet_RSISR" target="_blank">[Code]</a>
                                </p>
                            </div>
                        </div>

                        <div class="media">
                            <figure class="media-left">
                                <p class="image is-64x64">
                                    <img src="img/8.PNG" />
                                </p>
                            </figure>
                            <div class="media-content">
                                <p class="paper-title" style="font-size: large; font-weight: 500; color: black;">
                                    LCH: fast RGB-D salient object detection on CPU via lightweight convolutional network with hybrid knowledge distillation
                                </p>
                                <p class="paper-title">
                                    <i>Visual Computer, 2023</i>
                                </p>
                                <p class="paper-author is-italic">
                                    <strong>Binglu Wang</strong> , Fan Zhang, Yongqiang Zhao
                                </p>

                                <p class="paper-info">
                                    <a href="https://link.springer.com/article/10.1007/s00371-023-02898-8" target="_blank">[Paper]</a>
                                    <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:ZYEnjMpXAGQJ:scholar.google.com/&output=citation&scisdr=ChUMH1XLEJ-q1Cz_y-M:ABFrs3wAAAAAZLT50-PnGOahmr5_cgbkH2z-fGY&scisig=ABFrs3wAAAAAZLT503_CXkegeM6so4jr5W29xa8&scisf=4&ct=citation&cd=-1&hl=zh-CN" target="_blank">[Bibtex]</a>
                                    <!-- <a href="https://github.com/lartpang/CAVER" target="_blank">[Code]</a> -->
                                </p>
                            </div>
                        </div>

                        <div class="media">
                            <figure class="media-left">
                                <p class="image is-64x64">
                                    <img src="img\1.gif" />
                                </p>
                            </figure>
                            <div class="media-content">
                                <p class="paper-title" style="font-size: large; font-weight: 500; color: black;">
                                    Exploring Sub-Action Granularity for Weakly Supervised Temporal Action Localization
                                </p>
                                <p class="paper-title">
                                    <i>IEEE Transactions on Circuits and Systems for Video Technology, 2021</i>
                                </p>
                                <p class="paper-author is-italic">
                                    <strong>Binglu Wang</strong>, Xun Zhang, Yiongqang Zhao
                                </p>

                                <p class="paper-info">
                                    <a href="https://ieeexplore.ieee.org/abstract/document/9454500" target="_blank">[Paper]</a>
                                    <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:bZW2F6eXx9cJ:scholar.google.com/&output=citation&scisdr=ChUMH1XFEJ-q1Czxyug:ABFrs3wAAAAAZLT30ujbbhnkeidBkiIvmTnOICw&scisig=ABFrs3wAAAAAZLT30sluUQPqGLxQcCmKakW7rv8&scisf=4&ct=citation&cd=-1&hl=zh-CN" target="_blank">[Bibtex]</a>
                                    <!-- <a href="https://github.com/lartpang/CAVER" target="_blank">[Code]</a> -->
                                </p>
                            </div>
                        </div>

                        <div class="media">
                            <figure class="media-left">
                                <p class="image is-64x64">
                                    <img src="img\2.gif" />
                                </p>
                            </figure>
                            <div class="media-content">
                                <p class="paper-title" style="font-size: large; font-weight: 500; color: black;">
                                    Multiple Instance Graph Learning for Weakly Supervised Remote Sensing Object Detection
                                </p>
                                <p class="paper-title">
                                    <i>IEEE Transactions on Geoscience and Remote Sensing, 2021</i>
                                </p>
                                <p class="paper-author is-italic">
                                    <strong>Binglu Wang</strong>, Yongqiang Zhao, Xuelong Li
                                </p>

                                <p class="paper-info">
                                    <a href="https://ieeexplore.ieee.org/abstract/document/9585717" target="_blank">[Paper]</a>
                                    <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:d5rvuESx0koJ:scholar.google.com/&output=citation&scisdr=ChUMH1XFEJ-q1Cz-MEY:ABFrs3wAAAAAZLT4KEbkcqRH2JYgQ3fORcnREXs&scisig=ABFrs3wAAAAAZLT4KFs7UabEK-ZuMN_LYVSWnPE&scisf=4&ct=citation&cd=-1&hl=zh-CN" target="_blank">[Bibtex]</a>
                                    <!-- <a href="https://github.com/lartpang/CAVER" target="_blank">[Code]</a> -->
                                </p>
                            </div>
                        </div>


                        <div class="media">
                            <figure class="media-left">
                                <p class="image is-64x64">
                                    <img src="img/5.gif" />
                                </p>
                            </figure>
                            <div class="media-content">
                                <p class="paper-title" style="font-size: large; font-weight: 500; color: black;">
                                    POLO: Learning Explicit Cross-Modality Fusion for Temporal Action Localization
                                </p>
                                <p class="paper-title">
                                    <i>IEEE Signal Processing Letters, 2021</i>
                                </p>
                                <p class="paper-author is-italic">
                                    <strong>Binglu Wang</strong>, Le Yang, Yiongqiang Zhao
                                </p>

                                <p class="paper-info">
                                    <a href="https://ieeexplore.ieee.org/abstract/document/9362259" target="_blank">[Paper]</a>
                                    <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:fZmxKdi3q_gJ:scholar.google.com/&output=citation&scisdr=ChUMH1XMEJ-q1Cz-9Rk:ABFrs3wAAAAAZLT47RnX6v1FdcCLBkNGpNCniOA&scisig=ABFrs3wAAAAAZLT47XZfmPy6bb4f5XNPc25I14w&scisf=4&ct=citation&cd=-1&hl=zh-CN" target="_blank">[Bibtex]</a>
                                    <!-- <a href="https://github.com/lartpang/CAVER" target="_blank">[Code]</a> -->
                                </p>
                            </div>
                        </div>

                        <div class="media">
                            <figure class="media-left">
                                <p class="image is-64x64">
                                    <img src="img/6.jpg" />
                                </p>
                            </figure>
                            <div class="media-content">
                                <p class="paper-title" style="font-size: large; font-weight: 500; color: black;">
                                    PFWNet: Pretraining neural network via feature jigsaw puzzle for weakly-supervised temporal action localization
                                </p>
                                <p class="paper-title">
                                    <i>Neurocomputing, 2021</i>
                                </p>
                                <p class="paper-author is-italic">
                                    <strong>Binglu Wang</strong>, Yongqiang Zhao, Yani Zhang
                                </p>

                                <p class="paper-info">
                                    <a href="https://www.sciencedirect.com/science/article/abs/pii/S0925231221003441" target="_blank">[Paper]</a>
                                    <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:lI7mrac80XoJ:scholar.google.com/&output=citation&scisdr=ChUMH1XGEJ-q1Cz_UfI:ABFrs3wAAAAAZLT5SfIJAv9P2nfCVy2VhEtrZ5E&scisig=ABFrs3wAAAAAZLT5SVTDPrjjGmKbEJ0ut3cuEoo&scisf=4&ct=citation&cd=-1&hl=zh-CN" target="_blank">[Bibtex]</a>
                                    <!-- <a href="https://github.com/lartpang/CAVER" target="_blank">[Code]</a> -->
                                </p>
                            </div>
                        </div>

                        <div class="media">
                            <figure class="media-left">
                                <p class="image is-64x64">
                                    <img src="img/7.jpg" />
                                </p>
                            </figure>
                            <div class="media-content">
                                <p class="paper-title" style="font-size: large; font-weight: 500; color: black;">
                                    I2net: Mining intra-video and inter-video attention for temporal action localization
                                </p>
                                <p class="paper-title">
                                    <i>Neurocomputing, 2021</i>
                                </p>
                                <p class="paper-author is-italic">
                                    Wei Zhang, <strong>Binglu Wang*</strong> , Songhui Ma, Yani Zhang, Yongqiang Zhao
                                </p>

                                <p class="paper-info">
                                    <a href="https://www.sciencedirect.com/science/article/abs/pii/S092523122100343X" target="_blank">[Paper]</a>
                                    <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:OVv56XGUX8EJ:scholar.google.com/&output=citation&scisdr=ChUMH1XLEJ-q1Cz_Z3k:ABFrs3wAAAAAZLT5f3kvzcdxeVL4p7PWMhdamaY&scisig=ABFrs3wAAAAAZLT5f09c6L0SDwQAnZ7wiVhJ5Qc&scisf=4&ct=citation&cd=-1&hl=zh-CN" target="_blank">[Bibtex]</a>
                                    <!-- <a href="https://github.com/lartpang/CAVER" target="_blank">[Code]</a> -->
                                </p>
                            </div>
                        </div>

                    </div>



                    <div class="box" id="Publication">
                        <p class="title is-3">Conference Paper</p>

                        <div class="media">
                            <figure class="media-left">
                                <p class="image is-64x64">
                                    <img src="" />
                                </p>
                            </figure>
                            <div class="media-content">
                                <p class="paper-title" style="font-size: large; font-weight: 500; color: black;">
                                    Core: Cooperative reconstruction for multi-agent perception
                                </p>
                                <p class="paper-title">
                                    <i> Proceedings of the IEEE/CVF International Conference on Computer Vision 2023</i>
                                </p>
                                <p class="paper-author is-italic">
                                    Binglu Wang, Lei Zhang, Zhaozhong Wang, Yongqiang Zhao, Tianfei Zhou
                                </p>

                                <p class="paper-info">
                                    <a href="https://ieeexplore.ieee.org/document/10015667" target="_blank">[Paper]</a>
                                    <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:jumyW277thAJ:scholar.google.com/&output=citation&scisdr=ClG13cpmEIr-8CJMR5c:AFWwaeYAAAAAZYFKX5dYdcylDI1w9Mhb69tZUJM&scisig=AFWwaeYAAAAAZYFKX1ukqJXqtwqNh-2XEh17WRI&scisf=4&ct=citation&cd=-1&hl=zh-CN" target="_blank">[Bibtex]</a>
                                </p>
                            </div>
                        </div>
                    

                    <div class="box" id="Publication">
                        <p class="title is-3">Conference Paper</p>

                        <div class="media">
                            <figure class="media-left">
                                <p class="image is-64x64">
                                    <img src="" />
                                </p>
                            </figure>
                            <div class="media-content">
                                <p class="paper-title" style="font-size: large; font-weight: 500; color: black;">
                                    Multi-level Deep Learning Kalman Filter
                                </p>
                                <p class="paper-title">
                                    <i> IEEE International Conference on Advanced Robotics & Mechatronics 2023</i>
                                </p>
                                <p class="paper-author is-italic">
                                    Shi Yan, Yan Liang, <strong>Binglu Wang*</strong>
                                </p>

                                <p class="paper-info">
                                    <!-- <a href="https://ieeexplore.ieee.org/document/10015667" target="_blank">[Paper]</a>
                                    <a href="https://github.com/lartpang/CAVER" target="_blank">[Bibtex]</a>
                                    <a href="https://github.com/lartpang/CAVER" target="_blank">[Code]</a> -->
                                </p>
                            </div>
                        </div>

                        <div class="media">
                            <figure class="media-left">
                                <p class="image is-64x64">
                                    <img src="img/10.gif" />
                                </p>
                            </figure>
                            <div class="media-content">
                                <p class="paper-title" style="font-size: large; font-weight: 500; color: black;">
                                    Densitytoken: Weakly-Supervised Crowd Counting with Density Classification
                                </p>
                                <p class="paper-title">
                                    <i> IEEE International Conference on Acoustics, Speech, and Signal Processing, 2023</i>
                                </p>
                                <p class="paper-author is-italic">
                                    Zaiyi Hu, <strong>Binglu Wang*</strong>, Xuelong Li
                                </p>

                                <p class="paper-info">
                                    <a href="https://ieeexplore.ieee.org/abstract/document/10095402" target="_blank">[Paper]</a>
                                    <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:d1sLo7EJgOQJ:scholar.google.com/&output=citation&scisdr=ChUMH1XLEKiBhBf8d1E:ABFrs3wAAAAAZLT6b1HLVsOOk52BQVwe9PXr5AI&scisig=ABFrs3wAAAAAZLT6b-zn4HPsMuDIsJ5T263_nV0&scisf=4&ct=citation&cd=-1&hl=zh-CN" target="_blank">[Bibtex]</a>
                                    <a href="https://github.com/CodeMonsterPHD/DSFormer" target="_blank">[Code]</a>
                                </p>
                            </div>
                        </div>

                        <div class="media">
                            <figure class="media-left">
                                <p class="image is-64x64">
                                    <img src="img/9.PNG" />
                                </p>
                            </figure>
                            <div class="media-content">
                                <p class="paper-title" style="font-size: large; font-weight: 500; color: black;">
                                    GaTector: A Unified Framework for Gaze Object Prediction
                                </p>
                                <p class="paper-title">
                                    <i> IEEE Conference on Computer Vision and Pattern Recognition, 2022</i>
                                </p>
                                <p class="paper-author is-italic">
                                    <strong>Binglu Wang*</strong>, Tao Hu, Baoshan Li, Xiaojuan Chen, Zhijie Zhang
                                </p>

                                <p class="paper-info">
                                    <a href="https://openaccess.thecvf.com/content/CVPR2022/html/Wang_GaTector_A_Unified_Framework_for_Gaze_Object_Prediction_CVPR_2022_paper.html" target="_blank">[Paper]</a>
                                    <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:4Mu5DxeghsgJ:scholar.google.com/&output=citation&scisdr=ChUMH1XKEKiBhBf8DWw:ABFrs3wAAAAAZLT6FWw89tLnsB0dD9jx7gLvFu4&scisig=ABFrs3wAAAAAZLT6FUhckcgdM__Hc1apfisjuzY&scisf=4&ct=citation&cd=-1&hl=zh-CN" target="_blank">[Bibtex]</a>
                                    <a href="https://github.com/CodeMonsterPHD/GaTector-A-Unified-Framework-for-Gaze-Object-Prediction" target="_blank">[Code]</a>
                                </p>
                            </div>
                        </div>
                    </div>



                    <div class="box" id="project">
                        <p class="title is-3">Social Work</p>
                        <ul class="ml-4">
                            <li>中国指控学会（陕西）青年科学家俱乐部 轮值主席</li>
                        </ul>
                        <ul class="ml-4">
                            <li>IEEE ARM（自动化学会A类会议）副主编 </li>
                        </ul>
                        <ul class="ml-4">
                            <li>陕西省图形图像学学会理事 </li>
                        </ul>
                        <ul class="ml-4">
                            <li>IEEE TPAMI/IEEE TCYB/IEEE TIE/CVPR 等10+国际顶级期刊和重要会议的审稿人 </li>
                        </ul>
                        <ul class="ml-4">
                            <li>北京理工大学博士后联谊会理事长/北京博士后联谊会理事 </li>
                        </ul>
                    </div>

                    <div class="box" id="project">
                        <p class="title is-3">Teaching Achievements</p>
                        <ul class="ml-4">
                            <li>清华AIR-百度Apollo车路协同自动驾驶算法挑战赛 优胜奖</li>
                        </ul>
                        <ul class="ml-4">
                            <li>西工大教育实验学院大学生创新创业重点支持领域项目（全院唯一）</li>
                        </ul>
                    </div>

                    <div class="box" id="project">
                        <p class="title is-3">Awards</p>
                        <ul class="ml-4">
                            <li>陕西省高等学校科学技术一等奖(排名2/6)</li>
                        </ul>
                        <ul class="ml-4">
                            <li>中国产学研学会合作创新与促进优秀奖(排名4/10)</li>
                        </ul>
                        <ul class="ml-4">
                            <li>西北工业大学优秀毕业生</li>
                        </ul>
                    </div>


                    


                </div>
            </div>
        </div>
    </section>
</body>

</html>
